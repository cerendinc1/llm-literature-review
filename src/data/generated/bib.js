define({ entries : {
    "Abdelnabi_2024": {
        "abstract": "There is a growing interest in using Large Language Models (LLMs) as agents to tackle real-world tasks that may require assessing complex situations. Yet, we have a limited understanding of LLMs' reasoning and decision-making capabilities, partly stemming from a lack of dedicated evaluation benchmarks. As negotiating and compromising are key aspects of our everyday communication and collaboration, we propose using scorable negotiation games as a new evaluation framework for LLMs. We create a testbed of diverse text-based, multi-agent, multi-issue, semantically rich negotiation games, with easily tunable difficulty. To solve the challenge, agents need to have strong arithmetic, inference, exploration, and planning capabilities, while seamlessly integrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT), we show that agents can negotiate and consistently reach successful deals. We quantify the performance with multiple metrics and observe a large gap between GPT-4 and earlier models. Importantly, we test the generalization to new games and setups. Finally, we show that these games can help evaluate other critical aspects, such as the interaction dynamics between agents in the presence of greedy and adversarial players.",
        "author": "Abdelnabi, Sahar and Gomaa, Amr and Sivaprasad, Sarath and Sch\u00f6nherr, Lea and Fritz, Mario",
        "doi": "https://doi.org/10.60882/cispa.25233028.v1",
        "keywords": "type:technique, application:game_based, model:LLM, task:negotiation, evaluation:benchmarking, evaluation:ablation",
        "title": "LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games",
        "type": "preprint",
        "year": "2024"
    },
    "Chen_2023": {
        "abstract": "The comprehension of spoken language is a crucial aspect of dialogue systems, encompassing two fundamental tasks: intent classification and slot filling. Currently, the joint modeling approach for these two tasks has emerged as the dominant method in spoken language understanding modeling. However, the existing joint models have limitations in terms of their relevancy and utilization of contextual semantic features between the multiple tasks. To address these limitations, a joint model based on BERT and semantic fusion (JMBSF) is proposed. The model employs pre-trained BERT to extract semantic features and utilizes semantic fusion to associate and integrate this information. The results of experiments on two benchmark datasets, ATIS and Snips, in spoken language comprehension demonstrate that the proposed JMBSF model attains 98.80% and 99.71% intent classification accuracy, 98.25% and 97.24% slot-filling F1-score, and 93.40% and 93.57% sentence accuracy, respectively. These results reveal a significant improvement compared to other joint models. Furthermore, comprehensive ablation studies affirm the effectiveness of each component in the design of JMBSF.",
        "author": "Chen, Yan and Luo, Zhenghang",
        "doi": "https://doi.org/10.3390/s23052848",
        "journal": "Sensors",
        "keywords": "type:technique, application:intent_classification, model:LLM, task:joint_modeling",
        "number": "5",
        "publisher": "Switzerland: MDPI AG",
        "title": "Pre-Trained Joint Model for Intent Classification and Slot Filling with Semantic Feature Fusion",
        "type": "article",
        "volume": "23",
        "year": "2023"
    },
    "Du_2023": {
        "abstract": "Combining symbolic and subsymbolic methods has become a promising strategy as research tasks in AI grow increasingly complicated and require higher levels of understanding. Targeted Aspect-based Financial Sentiment Analysis (TABFSA) is an example of such complicated tasks, as it involves processes like information extraction, information specification, and domain adaptation. However, little is known about the design principles of such hybrid models leveraging external lexical knowledge. To fill this gap, we define anterior, parallel, and posterior knowledge integration and propose incorporating multiple lexical knowledge sources strategically into the fine-tuning process of pre-trained transformer models for TABFSA. Experiments on the Financial Opinion mining and Question Answering challenge (FiQA) Task 1 and SemEval 2017 Task 5 datasets show that the knowledge-enabled models systematically improve upon their plain deep learning counterparts, and some outperform state-of-the-art results reported in terms of aspect sentiment analysis error. We discover that parallel knowledge integration is the most effective and domain-specific lexical knowledge is more important according to our ablation analysis.",
        "author": "Du, Kelvin and Xing, Frank and Cambria, Erik",
        "doi": "https://doi.org/10.1145/3580480",
        "journal": "ACM Transactions on Management Information Systems",
        "keywords": "type:technique, application:sentiment_analysis, model:LLM, task:domain_adaptation",
        "number": "3",
        "publisher": "New York, NY: ACM",
        "title": "Incorporating Multiple Knowledge Sources for Targeted Aspect-based Financial Sentiment Analysis",
        "type": "article",
        "volume": "14",
        "year": "2023"
    },
    "Fernandez_2022": {
        "abstract": "Intent recognition is a key component of any task-oriented conversational system. The intent recognizer can be used first to classify the user\u2019s utterance into one of several predefined classes (intents) that help to understand the user\u2019s current goal. Then, the most adequate response can be provided accordingly. Intent recognizers also often appear as a form of joint models for performing the natural language understanding and dialog management tasks together as a single process, thus simplifying the set of problems that a conversational system must solve. This happens to be especially true for frequently asked question (FAQ) conversational systems. In this work, we first present an exploratory analysis in which different deep learning (DL) models for intent detection and classification were evaluated. In particular, we experimentally compare and analyze conventional recurrent neural networks (RNN) and state-of-the-art transformer models. Our experiments confirmed that best performance is achieved by using transformers. Specifically, best performance was achieved by fine-tuning the so-called BETO model (a Spanish pretrained bidirectional encoder representations from transformers (BERT) model from the Universidad de Chile) in our intent detection task. Then, as the main contribution of the paper, we analyze the effect of inserting unseen domain words to extend the vocabulary of the model as part of the fine-tuning or domain-adaptation process. Particularly, a very simple word frequency cut-off strategy is experimentally shown to be a suitable method for driving the vocabulary learning decisions over unseen words. The results of our analysis show that the proposed method helps to effectively extend the original vocabulary of the pretrained models. We validated our approach with a selection of the corpus acquired with the Hispabot-Covid19 system obtaining satisfactory results.",
        "author": "Fern\u00e1ndez-Mart\u00ednez, Fernando and Luna-Jim\u00e9nez, Cristina and Kleinlein, Ricardo and Griol, David and Callejas, Zoraida and Montero, Juan Manuel",
        "doi": "https://doi.org/10.3390/app12031610",
        "journal": "Applied Sciences",
        "keywords": "type:technique, application:intent_classification, model:LLM, method:vocabulary_extension",
        "number": "3",
        "publisher": "Basel: MDPI AG",
        "title": "Fine-Tuning BERT Models for Intent Recognition Using a Frequency Cut-Off Strategy for Domain-Specific Vocabulary Extension",
        "type": "article",
        "volume": "12",
        "year": "2022"
    },
    "Fields_2024": {
        "abstract": "Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer- based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",
        "author": "Fields, John and Chovanec, Kevin and Madiraju, Praveen",
        "doi": "https://doi.org/10.1109/ACCESS.2024.3349952",
        "journal": "IEEE Access",
        "keywords": "type:survey, application:sentiment_analysis, model:LLM",
        "publisher": "IEEE",
        "title": "A Survey of Text Classification with Transformers: How wide? How large? How long? How accurate? How expensive? How safe?",
        "type": "article",
        "volume": "12",
        "year": "2024"
    },
    "Hu_2024": {
        "abstract": "The development of game agents holds a critical role in advancing towards Artificial General Intelligence. The progress of Large Language Models (LLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of LLM-based game agents, centered around three core functional components: memory, reasoning and in/output. Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting & exploration games. Finally, we present an outlook of future research and development directions in this burgeoning field. A curated list of relevant papers is maintained and made accessible at: https://github.com/git-disl/awesome-LLM-game-agent-papers.",
        "author": "Hu, Sihao and Huang, Tiansheng and Liu, Gaowen and Kompella, Ramana Rao and Ilhan, Fatih and Tekin, Selim Furkan and Xu, Yichang and Yahn, Zachary and Liu, Ling",
        "doi": "https://doi.org/10.48550/arXiv.2404.02039",
        "keywords": "type:survey, application:game_based, model:LLM, task:multi-agent_interaction",
        "title": "A Survey on Large Language Model-Based Game Agents",
        "type": "preprint",
        "year": "2024"
    },
    "Huang_2023": {
        "abstract": "We develop FinBERT, a state-of-the-art large language model that adapts to the finance domain. We show that FinBERT incorporates finance knowledge and can better summarize contextual information in financial texts. Using a sample of researcher-labeled sentences from analyst reports, we document that FinBERT substantially outperforms the Loughran and McDonald dictionary and other machine learning algorithms, including na\u00efve Bayes, support vector machine, random forest, convolutional neural network, and long short-term memory, in sentiment classification. Our results show that FinBERT excels in identifying the positive or negative sentiment of sentences that other algorithms mislabel as neutral, likely because it uses contextual information in financial text. We find that FinBERT\u2019s advantage over other algorithms, and Google\u2019s original bidirectional encoder representations from transformers model, is especially salient when the training sample size is small and in texts containing financial words not frequently used in general texts. FinBERT also outperforms other models in identifying discussions related to environment, social, and governance issues. Last, we show that other approaches underestimate the textual informativeness of earnings conference calls by at least 18% compared to FinBERT. Our results have implications for academic researchers, investment professionals, and financial market regulators.",
        "author": "Huang, Allen H. and Wang, Hui and Yang, Yi",
        "doi": "https://doi.org/10.1111/1911-3846.12832",
        "journal": "Contemporary Accounting Research",
        "keywords": "type:technique, application:sentiment_analysis, model:LLM, task:domain_adaptation",
        "number": "2",
        "publisher": "Hoboken, USA: John Wiley & Sons, Inc",
        "title": "FinBERT: A Large Language Model for Extracting Information from Financial Text",
        "type": "article",
        "volume": "40",
        "year": "2023"
    },
    "Kramar_2022": {
        "abstract": "The success of human civilization is rooted in our ability to cooperate by communicating and making joint plans. We study how artificial agents may use communication to better cooperate in Diplomacy, a long-standing AI challenge. We propose negotiation algorithms allowing agents to agree on contracts regarding joint plans, and show they outperform agents lacking this ability. For humans, misleading others about our intentions forms a barrier to cooperation. Diplomacy requires reasoning about our opponents\u2019 future plans, enabling us to study broken commitments between agents and the conditions for honest cooperation. We find that artificial agents face a similar problem as humans: communities of communicating agents are susceptible to peers who deviate from agreements. To defend against this, we show that the inclination to sanction peers who break contracts dramatically reduces the advantage of such deviators. Hence, sanctioning helps foster mostly truthful communication, despite conditions that initially favor deviations from agreements.",
        "author": "Kram\u00e1r, J\u00e1nos and Eccles, Tom and Gemp, Ian and Tacchetti, Andrea and McKee, Kevin R. and Malinowski, Mateusz and Graepel, Thore and Bachrach, Yoram",
        "doi": "https://doi.org/10.1038/s41467-022-34473-5",
        "journal": "Nature Communications",
        "keywords": "type:technique, application:game_based, model:RL+LLM, evaluation:simulation, setting:game",
        "number": "1",
        "publisher": "London: Nature Publishing Group UK",
        "title": "Negotiation and Honesty in Artificial Intelligence Methods for the Board Game of Diplomacy",
        "type": "article",
        "volume": "13",
        "year": "2022"
    },
    "Xing_2025": {
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focus from massive data acquisition and new model training to human alignment and strategic elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA) due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage existing generative models in such a context. This study investigates the effectiveness of the new paradigm, that is, using LLMs without fine-tuning for FSA. Rooted in Minsky\u2019s theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed and applied to FSA. The framework instantiates specialized agents using prior guiding knowledge from both linguistics and finance. Then, a summative agent reasons on the aggregated agent discussions. Comprehensive evaluations using six FSA datasets show that the framework yields better accuracies compared to many alternative multi-LLM agent settings, especially when the discussion contents are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA and potentially other tasks. Implications for business and management have also been discussed.",
        "author": "Xing, Frank",
        "doi": "https://doi.org/10.1145/3688399",
        "journal": "ACM Transactions on Management Information Systems",
        "keywords": "type:technique, application:sentiment_analysis, model:LLM, task:financial_sentiment",
        "number": "1",
        "publisher": "ACM",
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "type": "article",
        "volume": "16",
        "year": "2025"
    },
    "Yang_2025": {
        "abstract": "The task of dialogue sentiment analysis aims to identify the sentiment polarity of utterances in the context of a dialogue. Pre-trained models often struggle to capture the logical structure of a dialogue, making this task challenging. To address this issue, we propose a dialogue sentiment analysis framework that leverages pre-training on dialogue structure. Our proposed framework includes three sub-tasks for pre-training: utterance order sorting, sentence backbone regularization, and sentiment shift detection. These tasks are designed to improve the model\u2019s ability to mine dialogue logical relationships and sentiment interactions. By focusing on learning the logical structure of dialogues and the perception of sentiment interactions, our framework is able to improve the performance of pre-trained models on recognizing the sentiment polarity of dialogues. This is demonstrated by the convincing results obtained on the public MEISD dataset.",
        "author": "Yang, Liang and Yang, Qi and Zeng, Jingjie and Peng, Tao and Yang, Zhihao and Lin, Hongfei",
        "doi": "https://doi.org/10.1007/s00530-025-01672-1",
        "journal": "Multimedia Systems",
        "keywords": "type:technique, application:sentiment_analysis, model:LLM, task:emotion_classification",
        "number": "98",
        "publisher": "Multimedia Systems",
        "title": "Dialogue sentiment analysis based on dialogue structure pre-training",
        "type": "article",
        "volume": "31",
        "year": "2025"
    },
    "Zhang_2025": {
        "abstract": "With the rapid advancement of human\u2013machine dialogue technology, sentiment analysis has become increasingly crucial. However, deep learning-based methods struggle with interpretability and reliability due to the subjectivity of emotions and the challenge of capturing emotion\u2013cause relationships. To address these issues, we propose a novel sentiment analysis framework that integrates structured commonsense knowledge to explicitly infer emotional causes, enabling causal reasoning between historical and target sentences. Additionally, we enhance sentiment classification by leveraging large language models (LLMs) with dynamic example retrieval, constructing an experience database to guide the model using contextually relevant instances. To further improve adaptability, we design a semantic interpretation task for refining emotion category representations and fine-tune the LLM accordingly. Experiments on three benchmark datasets show that our approach significantly improves accuracy and reliability, surpassing traditional deep-learning methods. These findings underscore the effectiveness of structured reasoning, knowledge retrieval, and LLM-driven sentiment adaptation in advancing emotion\u2013cause-based sentiment analysis.",
        "author": "Zhang, Xue and Wang, Mingjiang and Zhuang, Xuyi and Zeng, Xiao and Li, Qiang",
        "doi": "https://doi.org/10.3390/sym17040489",
        "journal": "Symmetry",
        "keywords": "type:technique, application:sentiment_analysis, model:LLM, task:emotion_classification",
        "number": "4",
        "publisher": "Symmetry",
        "title": "CDEA: Causality-Driven Dialogue Emotion Analysis via LLM",
        "type": "article",
        "volume": "17",
        "year": "2025"
    },
    "Zheng_2024": {
        "abstract": "Since the release of ChatGPT, large language models (LLMs) have played a huge role in various industries. In the field of games, we have used LLMs to act as intelligent AI NPC, which makes NPCs more intelligent. However, there is still an obvious obstacle -the LLMs lacks long-term memory and human-like memory mechanism. This flawed memory mechanism prevents NPCs from Long-term interaction and humanized memory based on conversation records. Recognizing the necessity of long-term memory and humanized memory, we proposed MemoryRepository, a memory mechanism for LLMs specifically used in the AI NPC field. MemoryRepository enables the model to have short-term memory and long-term memory. Short-term memory is more detailed and full, while long-term memory are more concise and partial. MemoryRepository is inspired by human memory and forgetting mechanisms. This mechanism allows AI NPCs to forget and summarize past conversation records, thereby providing long-term interaction capabilities. More importantly, this process of forgetting and summarizing the details of short-term memory into general long-term memories makes NPCs more human-like. MemoryRepository is versatile and can adapt to closed source models such as ChatGPT and open source models such as ChatGLM. To Intuitively verify the effectiveness of MemoryRepository in the field of AI NPC, we created an example in which all NPCs are represented by LLMs adapted to MemoryRepository. The example shows that by embedding LLM in MemoryRepository and fine-tuning NPCs character dialogue data, AI NPC can conduct better long-term conversations and appear more human-like during the interaction process. To validate the effectiveness of MemoryRepository, one hundred pieces of NPCs dialogue data were created and then quantitatively analyzed through evaluation indicators. The analysis results show that NPCs equipped with MemoryRepository can summarize and forget past memories, which enables it to have the ability to hold long-term conversations and conduct more human-like conversations.",
        "author": "Zheng, Shijie and He, Keith and Yang, Le and Xiong, Jie",
        "doi": "https://doi.org/10.1109/ACCESS.2024.3393485",
        "journal": "IEEE Access",
        "keywords": "type:technique, application:game_based, model:LLM",
        "publisher": "Piscataway: IEEE",
        "title": "MemoryRepository for AI NPC",
        "type": "article",
        "volume": "12",
        "year": "2024"
    }
}});